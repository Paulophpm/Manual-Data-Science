# Breve Manual para Data Science
Esse √© um manual simples e pr√°tico para guiar o andamento de projetos de ci√™ncia de dados utilizando o Phyton, a fim de deixar o processo de an√°lise mais organizado aumentando a produtividade para focar mais nos processos de data, disponibilizando alguns templates para ser utilizados como base e algumas dicas de c√≥digo para deixar o seu projeto mais clean e objetivo.

Esse projeto tem como objetivo que voc√™ entenda a teoria por tr√°s do c√≥digo das etapas necess√°rias a serem realizadas em um projeto de data science, a depender do projeto as etpas e dos dados utilizados, pode ser que seja necess√°rio pular algumas etapas, ou at√© menos durante o seu projeto seja necess√°rio voltar a uma etapa anterior para resilver algum problema.

# 1 - Pre-Carregamento dos Dados;

<aside>
üí° Verificar os dados que s√£o necess√°rios para come√ßar a construir o projetos e verificar algumas de suas propriedades. Assim j√° ter√° uma certa no√ß√£o de alguns processamentos que v√£o ser necess√°rios ser realizado no decorrer do projeto.
</aside>

Algumas fontes de dados j√° possuem Metadados, que traz basicamente todas as propriedades do conjunto de dados em quest√£o. Como o tipo de objeto de cada coluna, tamanho do arquivo, tamanho do dataset‚Ä¶ o que j√° facilita bastante a nossa vida.

Por√©m nem todas as fontes v√£o ter de forma t√£o simples e f√°cil esses metadados, por isso gosto sempre de criar um resumo com algumas propriedades b√°sicas do conjunto de dados, o que me d√° um no√ß√£o do que vou precisar realizar e assim que consigo ter uma melhor dimens√£o das an√°lises.

[Template](https://www.notion.so/Template-000891d83baa45f5913b6afb2f72492d)

### 1.1 - Origem
Ao pensar na origem dos dados, √© importante entender se o seu projeto utuliza mais de uma origem de fonte de dados, e qual √© o processo para acessar essa fonte

[Template Origem](https://www.figma.com/file/a6JA3XC5vdV7VTSBWreZ7H/Template?node-id=0%3A1&t=EfKPDgftA4OTLkSp-1)

- Localiza√ß√£o da fonte de dados (Sharepoint, Web, Postgree, Kaggle, MongoDB‚Ä¶);
- Verificar credenciais para acesso dos dados (Organizacional, Chave de acesso...);
- Atualiza√ß√µes dos dados (em quanto tempo esses dados s√£o atualizados?)

### 1.2 - Metadados

- Verificar a Extens√£o dos Dados (csv, json, txt‚Ä¶);
- Formato do arquivo;
- Verificar encoding;
- Delimitador;
- Tamaho dos dados;
- Conex√£o com os dados

# 2. Carregamento dos Dados
<aside>
üí° Carregar os dados da forma correta √© imprescind√≠vel para evitar poss√≠vel problemas durante o decorrer do seu projeto, assim como carregar apenas os pacotes que forem necess√°rio ou at√© mesmo apenas os m√≥dulos dos pacotes que forem efetivamente utilizados. Dessa forma √© poss√≠vel deixar o seu projeto mais leve, tanto de mem√≥ria quanto de processamento.
</aside>

### 2.1 Importa√ß√£o

```python
# importas os pacotes que geralmente s√£o mais utilizados
# lembrando de carregar apenas o que for utilizar
import pandas as pd 
import numpy as np
import matplotlib.pyplot as mlp
import seaborn as sns
```

### 2.2 Configurando as importa√ß√µes

```python
# Configura√ß√£o dos plots do NumPy
np.set_printoptions(suppress = True, linewidth = 200, precision = 2)
# suppress = 
# linewidth = 
# precision = quantidade de casas decimais
# configura√ß√£o de impress√£o do Pandas
pd.
```

```python
# Par√¢metros de configura√ß√£o Matplotlib
from matplotlib import rcParams

rcParams['figure.figsize'] = 12, 4 # tamanho da grade da figura a ser criada
rcParams['lines.linewidth'] = 3 # quantidade de linhas
rcParams['xtick.labelsize'] = 'x-large' # largura do eixo x √© o total da tela dispon√≠vel
rcParams['ytick.labelsize'] = 'x-large' # largura do exio y √© o total da tela dispon√≠vel

# Par√¢metros de configura√ß√£o Seasborn
```
## Carregando Dataset

<aside>
üí° Carregar o dataset de acordo com a extens√£o do artigo, e garantir que seja todos os dados sejam devidamente carregados;

</aside>

Pontos a Verificar:

- Encoding;
- Delimitador;
- Escape de Caractere;
- Header (Cabe√ßalho);
- Concatenar tabelas (recomendo ap√≥s a limpeza);

# 3 - Data Wrangling

<aside>
üí° Data Wrangling (ou Data Munging) √© o processo de limpeza, transforma√ß√£o e organiza√ß√£o dos dados brutos para torn√°-los mais adequados para an√°lise de dados. Isso pode incluir a remo√ß√£o de dados ausentes, a corre√ß√£o de dados incorretos ou inconsistentes, a combina√ß√£o de v√°rias fontes de dados em um √∫nico conjunto de dados, entre outras tarefas de prepara√ß√£o de dados..

</aside>

### 1.1 - Formata√ß√£o de Valores

Formatar corretamente, ou verificar se as colunas do seu dataset est√£o devidamente configuradas no formato correto para que seja analisadas de formar correta em breve. 

Mesmo que alguns valores j√° venham formatado como valores num√©ricos, √© importante verificar se por acaso eles n√£o foram carregados em um tipo num√©rico diferetnte

Uma boa pr√°tica √©, se poss√≠vel separa o dataset em quest√£o em dois, um com valores num√©ricos e outro com valores strings, pois dessa forma poder√° ser mais f√°cil tratar as colunas j√° que vai ser poss√≠vel tratar mais de uma coluna de uma √∫nica vez.

<aside>
üí° Separar o dataset em dados num√©ricos e dados do tipo string para facilitar a limpeza dos dados em quest√£o

</aside>

- Formata√ß√£o dos valores Num√©ricos;
    - Data/Hora;
    - Moeda (qual regi√£o)
    - CEP;
    - Latitude;
    - Tipo num√©rico (Double, int,);

No caso de caracteres do tipo string, √© importante observar se todos os caracteres foram devidamente carregados com o encoding correto, e se h√° algum escape de caractere.

- Formata√ß√£o de Caracteres Strings:
    - Endere√ßo por extenso;
    - Cidade;
    - Estado;

